{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "329a945a-22e8-4fac-a17d-faf659b3f04a",
   "metadata": {},
   "source": [
    "# Hate Speech Detection with Machine Learning\n",
    "\n",
    "Hate speech is one of the serious issues we see on social media platforms like Twitter and Facebook daily. Most of the posts containing hate speech can be found in the accounts of people with political views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e176e2b6-5019-415b-acf6-c878443b3f6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a96b6140-5a51-4d80-87d2-4203322e24ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.util import pr\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c29d47a9-db88-4342-b4d7-4d6856cf6c9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ba3bc97-3ae9-4479-a620-4b07e13e5305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "441d8a12-0957-41cd-a82c-093ab888e39e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e96f8c6-18cf-43e4-9996-2bb0876390c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stemmer = nltk.SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67ce94a3-1054-4280-a518-9365444986ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dde91f3-0503-4c36-9673-f7cb8aee8555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6da3fe9a-a44b-40a5-b0e2-b4a60e7fc52f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aser\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84db08cf-7659-4241-95df-677edf0128f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "baa0c7f8-a789-4d0e-9f57-fa5df533e1e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"twitter.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e716ba80-c12b-4a40-af85-1f8a81578d73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0               0      3            0                   0        3      2   \n",
      "1               1      3            0                   3        0      1   \n",
      "2               2      3            0                   3        0      1   \n",
      "3               3      3            0                   2        1      1   \n",
      "4               4      6            0                   6        0      1   \n",
      "...           ...    ...          ...                 ...      ...    ...   \n",
      "24778       25291      3            0                   2        1      1   \n",
      "24779       25292      3            0                   1        2      2   \n",
      "24780       25294      3            0                   3        0      1   \n",
      "24781       25295      6            0                   6        0      1   \n",
      "24782       25296      3            0                   0        3      2   \n",
      "\n",
      "                                                   tweet  \n",
      "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
      "...                                                  ...  \n",
      "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
      "24779  you've gone and broke the wrong heart baby, an...  \n",
      "24780  young buck wanna eat!!.. dat nigguh like I ain...  \n",
      "24781              youu got wild bitches tellin you lies  \n",
      "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
      "\n",
      "[24783 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a370f4-6ed8-4f67-840d-4a924c90def7",
   "metadata": {},
   "source": [
    "*add a new column to this dataset as labels which will contain the values as:\n",
    "\n",
    "*Hate Speech*\n",
    "\n",
    "*Offensive Language*\n",
    "\n",
    "*No Hate and Offensive*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "583de408-8ec8-4eb9-a108-e2432ff7809e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[\"labels\"] = data[\"class\"].map({0: \"Hate Speech\", \n",
    "                                   1: \"Offensive Language\", \n",
    "                                   2: \"No Hate and Offensive\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e9b8fe2-9a9c-4aa8-acd8-e43e06c034b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet                 labels  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  No Hate and Offensive  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...     Offensive Language  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...     Offensive Language  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...     Offensive Language  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...     Offensive Language  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476da955-b7d6-4cb3-bc72-af57a227bc4b",
   "metadata": {},
   "source": [
    "*Here I select only the tweet and labels columns for the rest of the task of training a hate speech detection model:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb52e26f-389c-4885-9679-e5af671bc0db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data[[\"tweet\", \"labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae81a6c4-f6ed-4584-bb67-4461f6ea9d41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet                 labels\n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  No Hate and Offensive\n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...     Offensive Language\n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...     Offensive Language\n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...     Offensive Language\n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...     Offensive Language\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a4809-0488-4324-a648-8047e6fe7fd6",
   "metadata": {},
   "source": [
    "*here is the function to clear text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f64bed6d-a4fc-43d9-8369-983840c54580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopwords]\n",
    "    text=\" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text=\" \".join(text)\n",
    "    return text\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52800393-aebf-4f2d-91dd-d06feb6202f8",
   "metadata": {},
   "source": [
    "*split the dataset into training and test sets and train a machine learning model for the task of hate speech detection:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "968f176e-b89b-4dc6-8dc5-4bb0dc82adec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.array(data[\"tweet\"])\n",
    "y = np.array(data[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "622ea0b9-bb91-450b-b613-69d041e818f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "62a14699-d409-4ec5-9a34-0d747c90fece",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = cv.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7401eadc-d0a9-4561-bd00-8b439f36cd3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "784860c5-37a2-4fac-b51f-79da4291043b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9f2c3512-e623-475e-af83-789a5634309b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8767575498227167"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "67e5023a-6cc6-4235-bb4d-1a80db5f64a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.67575498227167"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = clf.score(X_test, y_test) * 100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd133587-26c0-4317-9e21-0fa1aefa9238",
   "metadata": {},
   "source": [
    "### Now let’s test this machine learning model to see if it detects hate speech or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "05aec760-eef3-42b8-9b4e-df0f6f75655f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Offensive Language']\n"
     ]
    }
   ],
   "source": [
    "sample = \"Let's unite and kill all the people who are protesting against the government\"\n",
    "data = cv.transform([sample]).toarray()\n",
    "print(clf.predict(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c14665-ad0f-4cb5-9b85-f81f0ad2ac71",
   "metadata": {},
   "source": [
    "# Summary\n",
    "So this is how you can train a machine learning model for the task of detecting hate speech by using the Python programming language. Hate speech is one of the serious issues we see on social media platforms like Twitter and Facebook daily. Most of the posts containing hate speech can be found in the accounts of people with political views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1c0e7d-8b30-4cd9-bbf3-80f62b29ffe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ca171e6-d685-4d66-b26e-27685e4c2d1d",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "01cdc2b7-66ba-4591-84e4-4fb19dfdccf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377db8c8-b962-4a62-aeb7-b16a49ecb71e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "01522752-2b10-4f2b-a190-43aa46f07527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump(clf, open('hate_speech_detection_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8683740-5836-4028-908e-ae02d463f14f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb3f0ae4-b3d8-41f7-9c33-e1c85a78fbb8",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "418a3cab-76c0-4c16-bab6-055f22181bf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8767575498227167\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open('hate_speech_detection_model.pkl', 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f75260-b308-439c-a735-c52b17f3e7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
